{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f5d731c-5d83-46a9-801d-4a9877b45e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ffdc6-edf1-4677-99de-9c8c1dafb739",
   "metadata": {},
   "source": [
    "### INITIER LES DOSSIERS DE TEST ET D'ENTRAINEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64796df8-84de-46b0-8046-78d6dd661c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    " TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764b5abd-460e-470c-90cc-b69f19834c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataFrame(dir):\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imageName in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir, label, imageName))\n",
    "            labels.append(label)\n",
    "            print(labels,\"completed\")\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685c267b-3d70-4f7b-b09a-c32db33f8a7f",
   "metadata": {},
   "source": [
    "### CREATION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6699412f-22c3-4185-b6a6-f2e6ba2329d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['labels'] = createDataFrame(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc44b07-5085-4edc-95bd-5d1469f34e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['labels'] = createDataFrame(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d00263-3b8e-425c-bc5e-ce0cbe86ec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image    labels\n",
      "0       images/test\\angry\\10052.jpg     angry\n",
      "1       images/test\\angry\\10065.jpg     angry\n",
      "2       images/test\\angry\\10079.jpg     angry\n",
      "3       images/test\\angry\\10095.jpg     angry\n",
      "4       images/test\\angry\\10121.jpg     angry\n",
      "...                             ...       ...\n",
      "7061  images/test\\surprise\\9806.jpg  surprise\n",
      "7062  images/test\\surprise\\9830.jpg  surprise\n",
      "7063  images/test\\surprise\\9853.jpg  surprise\n",
      "7064  images/test\\surprise\\9878.jpg  surprise\n",
      "7065   images/test\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec514ead-b62c-4730-ae4a-700dd0b673fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90717cc-8f20-4008-8147-3adc6e1e4da0",
   "metadata": {},
   "source": [
    "### EXTRACTION DE TOUS LES VARIABLES INDEPENDANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3950f2b6-12d8-47a0-9b6d-4104becc55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook  import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa6619a-a7e9-448b-bd24-b4283b426e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale = True)\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60f348a8-cd5c-49ef-96eb-3a39829c2653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ffa752b69c46b88a317d359b6fad5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP G5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_features = extractFeatures(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63a7356c-a0ad-48d0-83a6-ce188093ea9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87f37dcb4ff4046bd4076ba13a5748c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extractFeatures(test['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd9209-6a5b-4a13-917a-428dc95b18ea",
   "metadata": {},
   "source": [
    "### TOUJOURS LES FAIRES EN FLOAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "405a8ce8-a810-42c7-af0c-ecb369802726",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240d47f-0e19-49a2-b229-1c1c31cc0f25",
   "metadata": {},
   "source": [
    "### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbd53b93-21f6-48c4-a74c-f98decfeb41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83afd500-7207-41dd-b7c4-8836c55298bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad029015-2cd2-4ac2-87b2-d1632db09622",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['labels'])\n",
    "y_test = le.transform(test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6d4d1dc-13a3-440c-a286-df335de79e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes=7)\n",
    "y_test = to_categorical(y_test,num_classes=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7a227-29cd-4e86-a25b-4eaa7f2c6184",
   "metadata": {},
   "source": [
    "### CREATION DES LAYERS DU RESEAU DES NEURONNES( LES HIDDEN LAYERS ET FULLY CONNECTED LAYERS)/ ICI ON UTILISE L'API SEQUENTIEL DE KERAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "624873b1-f5a8-4daa-a1b5-3be2f7de64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0da4418e-384e-4dba-b695-1ff0124d2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "#Conv 2D layers\n",
    "model.add(Conv2D(128,kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256,kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512,kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "#layers connecté\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#final output\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99ee66b6-8290-4318-bbbb-afa3c041c23c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "226/226 [==============================] - 704s 3s/step - loss: 1.8060 - accuracy: 0.2477 - val_loss: 1.7037 - val_accuracy: 0.3038\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 689s 3s/step - loss: 1.6176 - accuracy: 0.3597 - val_loss: 1.4776 - val_accuracy: 0.4339\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 692s 3s/step - loss: 1.4659 - accuracy: 0.4325 - val_loss: 1.3515 - val_accuracy: 0.4846\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 687s 3s/step - loss: 1.3787 - accuracy: 0.4689 - val_loss: 1.2880 - val_accuracy: 0.5144\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 689s 3s/step - loss: 1.3205 - accuracy: 0.4937 - val_loss: 1.2202 - val_accuracy: 0.5393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1209b47f850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile (\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss ='categorical_crossentropy',\n",
    "                    metrics='accuracy',\n",
    "                )\n",
    "model.fit(x = x_train, y = y_train, batch_size=128, epochs=5 , validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5840fa24-15fa-4c7b-9a51-eb25abad2a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP G5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open('emotiondetector.json','w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save('emotiondetector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a66e0e2-ad96-40b3-887e-bcb88367bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f9f1e79-c4b6-435b-b67c-4717ef2ab421",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'facialemotionmodel.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m json_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacialemotionmodel.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model_json \u001b[38;5;241m=\u001b[39m json_file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      3\u001b[0m json_file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'facialemotionmodel.json'"
     ]
    }
   ],
   "source": [
    "json_file = open(\"facialemotionmodel.json\",\"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"facialemotionmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a062571a-35b1-45ad-9749-8695a93c280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99a99641-249a-44ea-8e2e-99c48b1577b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    features = []\n",
    "    img = load_img(image,grayscale = True)\n",
    "    img = np.array(img)\n",
    "    features.append(img)\n",
    "    features = np.array(features)\n",
    "    features.reshape(len(features),48,48,1)\n",
    "    return features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "186ef1c0-b700-44fa-85b8-cf6ac7363040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is angry ....\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "model prediction is angry\n"
     ]
    }
   ],
   "source": [
    "image = 'images/train/angry/22.jpg'\n",
    "print(\"original image is angry ....\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is\", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31d930a8-6c56-4d36-b63e-74fd5ccf54a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is angry ....\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "model prediction is sad\n"
     ]
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is angry ....\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is\", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fc12f20-66d8-4745-adef-74d6cdedf4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d751db78-5690-49ab-b3d2-e1dc0e94dfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is angry ....\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "model prediction is sad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x120d25fb970>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = 'images/test/sad/231.jpg'\n",
    "print(\"original image is angry ....\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is\", pred_label)\n",
    "plt.imshow(img.reshape(48,48), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b24394f-6656-4035-a4ec-01026eb82d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/221 - 32s - loss: 1.2202 - accuracy: 0.5393 - 32s/epoch - 146ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2201662063598633, 0.5393433570861816]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = x_test, y = y_test, batch_size=32, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457bf70-413e-4e44-b7ad-cb045099545d",
   "metadata": {},
   "source": [
    "### TEST SUR L'API SUBCLASSING DE KERAS => BLOCAGES RESSOURCES MACHINES solutions: AZURES ET GOOGLE COLABS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a829a9a-1e0a-4e10-987d-2add0c8d106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Add, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def identity_block(X, f, filters):\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, s=2):\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3)(X_shortcut)\n",
    "    \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def ResNet50(input_shape=(224, 224, 3), classes=1000):\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(X_input)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    \n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    \n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    \n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "    \n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
